# -*- coding: utf-8 -*-
"""tsa_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dd1lfHPrf8w8gKkJmg70z15tmdmZidr1

# Preprocessing
"""

# Import required Libs for Preprocessing

import pandas as pd
from sklearn.model_selection import train_test_split

df= pd.read_csv('dataset.csv', sep=',')
df.head()

# Shape of Dataset

print("Number of Rows: " + str(df.shape[0]))
print("Number of Columns: " + str(df.shape[1]))

# Select Required Columns Only

tweet_df = df[['label','tweet']]

tweet_df.head()

# Select only Positive and Negative Reviews

# tweet_df = tweet_df[tweet_df['airline_sentiment'] != 'neutral']

# Attribute and Labels
y = df.label
X = df.tweet

# Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Checking Train Set

print("Training Set X Items: " + str(len(X_train)))
print("Training Set y Items: " + str(len(y_train)))

# Checking Test Set

print("Test Set X Items: " + str(len(X_test)))
print("Test Set y Items: " + str(len(y_test)))

# Getting required labels only and encoding

review_labels_train = y_train.factorize()

review_labels_train[0]

# Check Review Labels
review_labels_train[1]

"""# Next"""

# Importing required tf modules
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

vocab = X_train.values
vocab

# Vectorize a text corpus, by turning each text into sequence of integers

tokenizer = Tokenizer(num_words=8000,oov_token='OOV')
tokenizer.fit_on_texts(vocab)

vocab_size = len(tokenizer.word_index) + 1

print(tokenizer)
print(vocab_size)

len(tokenizer.word_index)

# # To save the tokenized vocab for Web app
import pickle
with open('sentiment.pickle', 'wb') as handle:
   pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

# Store and Padding Converted Sequences
tweet = X_train.values

tweet_seqs = tokenizer.texts_to_sequences(tweet)

padded_sequence_train = pad_sequences(tweet_seqs, maxlen=200)
print(padded_sequence_train)

# Check padded sequence element

print(padded_sequence_train[0])

# Build the model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.layers import SpatialDropout1D
from tensorflow.keras.layers import Embedding

embedding_vector_length = 32

model = Sequential()
model.add(Embedding(vocab_size, embedding_vector_length,     
                                     input_length=200) )
model.add(SpatialDropout1D(0.25))
model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])
print(model.summary())

# # Used to save trained model 

model.save("sentiment.h5")
# print("Model Saved")

"""# Train Model"""

# Training the model
trained = model.fit(padded_sequence_train,review_labels_train[0],
                  validation_split=0.2, epochs=5, batch_size=32)

# Encoding and Padding Test Data to Check Accuracy

encoded_docs = tokenizer.texts_to_sequences(X_test)
padded_sequence_test = pad_sequences(encoded_docs, maxlen=200)
print(padded_sequence_test)

sentiment_label_test = y_test.factorize()
sentiment_label_test[0]

score = model.evaluate(padded_sequence_test,sentiment_label_test[0],verbose=0)

print("Accuracy: {}".format(score[1]))

"""# Load Model"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras import models

#Code to load the saved model
model = models.load_model('sentiment.h5')
print("Model Loaded")
model.summary()

score = model.evaluate(padded_sequence_test,sentiment_label_test[0],verbose=0)

"""# Accuracy"""

print("Accuracy: {}".format(score[1]))

"""# Test Run"""

import pickle
with open('sentiment.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

len(tokenizer.word_index)

# Test Review Sentence

test_word ="""
i have never had a chance to vote for a presidential candidate i was excited about and this cycle looks to be no different.
"""

# To
tw = tokenizer.texts_to_sequences([test_word])
tw = pad_sequences(tw,maxlen=200)

tw

prediction = int(model.predict(tw).round().item())
outcome = str(review_labels_train[1][prediction])

print("Actual Review: " + test_word)
print("\nSentiment Analysis Outcome ==> The review shows " + str(review_labels_train[1][prediction])+ " sentiment.")
print("\n======================================================================================")

print("\nAccuracy Criteria \n\nProbability Closer to 0 == Negative Sentiment\nProbability Closer to 1 == Positive Sentiment")

prob = model.predict(tw)[0][0]

print("\n ==> Probability is " + str(prob)+ " (" + outcome + ")")

